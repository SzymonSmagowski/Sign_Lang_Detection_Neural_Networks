{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "root_dir = 'D:\\\\Alphabet'\n",
    "dest_dir = 'D:\\\\frames'\n",
    "\n",
    "if not os.path.exists(dest_dir):\n",
    "    os.mkdir(dest_dir)\n",
    "\n",
    "# To list what are the directories - train, test\n",
    "data_dir_list = os.listdir(root_dir)\n",
    "\n",
    "def vid_to_frames():\n",
    "    for data_dir in data_dir_list: # read the train  directory one \n",
    "        data_path = os.path.join(root_dir,data_dir) # 'Alphabet/train'\n",
    "        dest_data_path = os.path.join(dest_dir,data_dir) # 'frames/train'\n",
    "        if not os.path.exists(dest_data_path):\n",
    "            os.mkdir(dest_data_path)\n",
    "        \n",
    "        activity_list = os.listdir(data_path) # there are  individual  letters directories ['A', 'Ä„', 'B'.....] etc\n",
    "        \n",
    "        for activity in activity_list: # loop over every letter folder\n",
    "            activity_path = os.path.join(data_path,activity) # 'Alphabet/train/A'\n",
    "            dest_activity_path = os.path.join(dest_data_path,activity) # 'frames/train/A'\n",
    "            if not os.path.exists(dest_activity_path):\n",
    "                os.mkdir(dest_activity_path)\n",
    "            write_frames(activity_path,dest_activity_path)\n",
    "    \n",
    "def write_frames(activity_path,dest_activity_path):\n",
    "    # read the list of video from 'Alphabet/train/A' - [A1.mp4,A2.mp4, ......]\n",
    "    vid_list = os.listdir(activity_path) \n",
    "    for vid in vid_list: # A1.mp4\n",
    "        dest_folder_name = vid[:-4] # v_Archery_g01_c01\n",
    "        dest_folder_path = os.path.join(dest_activity_path,dest_folder_name) # 'frames/train/A/A1'\n",
    "        if not os.path.exists(dest_folder_path):\n",
    "            os.mkdir(dest_folder_path)\n",
    "            \n",
    "        vid_path = os.path.join(activity_path,vid)  # 'Alphabet/train/A/A1.mp4'\n",
    "        print ('video path: ', vid_path)\n",
    "        cap = cv2.VideoCapture(vid_path) # initialize a cap object for reading the video\n",
    "        \n",
    "        ret=True\n",
    "        frame_num=0\n",
    "        while ret:\n",
    "            ret, img = cap.read()\n",
    "            output_file_name = 'img_{:06d}'.format(frame_num) + '.png' # img_000001.png\n",
    "            # output frame to write 'frames/train/A/A1/img_000001.png'\n",
    "            output_file_path = os.path.join(dest_folder_path, output_file_name)\n",
    "            frame_num += 1\n",
    "            #print(\"Frame no. \", frame_num)\n",
    "            try:\n",
    "                #cv2.imshow('img',img)\n",
    "                cv2.waitKey(5)\n",
    "                cv2.imwrite(output_file_path, img) # writing frames to defined location\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "            if ret==False:\n",
    "                cv2.destroyAllWindows()\n",
    "                cap.release()\n",
    "if __name__ == '__main__':\n",
    "    vid_to_frames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "DESIRED_HEIGHT = 480\n",
    "DESIRED_WIDTH = 480\n",
    "\n",
    "\n",
    "def resize_and_show(image):\n",
    "  h, w = image.shape[:2]\n",
    "  if h < w:\n",
    "    img = cv2.resize(image, (DESIRED_WIDTH, math.floor(h/(w/DESIRED_WIDTH))))\n",
    "  else:\n",
    "    img = cv2.resize(image, (math.floor(w/(h/DESIRED_HEIGHT)), DESIRED_HEIGHT))\n",
    "  return img\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            img=resize_and_show(img)\n",
    "            images.append(img)\n",
    "    return images\n",
    "\n",
    "\n",
    "images=load_images_from_folder(\"C:\\\\Users\\\\HP\\\\Desktop\\\\video_to_frames\\\\frames\\\\train\\\\B\\\\1 (3)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run MediaPipe Hands.\n",
    "output_path='C:\\\\Users\\\\HP\\\\Desktop\\\\video_to_frames\\\\output\\\\B'\n",
    "flag=0\n",
    "counter=0\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=True,\n",
    "    max_num_hands=2,\n",
    "    min_detection_confidence=0.7) as hands:\n",
    "  for image in images:\n",
    "    if(flag==1):\n",
    "      cv2.destroyAllWindows()\n",
    "      break\n",
    "    # Convert the BGR image to RGB, flip the image around y-axis for correct \n",
    "    # handedness output and process it with MediaPipe Hands.\n",
    "    results = hands.process(cv2.flip(cv2.cvtColor(image, cv2.COLOR_BGR2RGB), 1))\n",
    "\n",
    "    # Print handedness (left v.s. right hand).\n",
    "    #print(f'Handedness of {name}:')\n",
    "    print(results.multi_handedness)\n",
    "\n",
    "    if not results.multi_hand_landmarks:\n",
    "      continue\n",
    "    # Draw hand landmarks of each hand.\n",
    "    #print(f'Hand landmarks of {name}:')\n",
    "    image_hight, image_width, _ = image.shape\n",
    "    annotated_image = cv2.flip(image.copy(), 1)\n",
    "    for hand_landmarks in results.multi_hand_landmarks:\n",
    "      # Print wrist finger tip coordinates.\n",
    "      if(hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].y<0.4):\n",
    "        counter+=1\n",
    "        print(\n",
    "            f'wrist tip coordinate: (',\n",
    "            f'{hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x }, '\n",
    "            f'{hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].y })'\n",
    "        )\n",
    "        mp_drawing.draw_landmarks(\n",
    "            annotated_image,\n",
    "            hand_landmarks,\n",
    "            mp_hands.HAND_CONNECTIONS,\n",
    "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "            mp_drawing_styles.get_default_hand_connections_style())\n",
    "        img=resize_and_show(cv2.flip(annotated_image, 1))\n",
    "        cv2.imwrite(os.path.join(output_path,f'B{counter}.png') ,img)\n",
    "        #cv2.imshow('img',img)\n",
    "        if cv2.waitKey(5) & 0xFF == 27:\n",
    "          flag=1\n",
    "          break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
